{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Decision Making\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the two-dimensional, discrete random variable $X = [X_1\\ X_2]^\\top$ subjected to the joint probability density $p_X$ as described in the following table.\n",
    "<div style=\"text-align: center\">$\\begin{array}{c|cc} p_X(X_1, X_2)  & X_2 = 0 & X_2 = 1 \\\\ \\hline\\hline X_1 = 0 & 0.4 & 0.3 \\\\ X_1 = 1 & 0.2 & 0.1\\end{array}$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Compute the marginal probability densities $p_{X1}, p_{X2}$ and the conditional probability $P(X_2 = 0|X_1 = 0)$ as well as the expected value $\\mathbb{E}[X]$ and the covariance matrix $\\mathbb{E}[(X - \\mathbb{E}[X])(X - \\mathbb{E}[X])^\\top]$ by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "[1 4 7 2 5 8 3 6 9]\n",
      "[0 2 3 1 2 4 1 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(1,10).reshape(3,3)\n",
    "print(x.ravel())\n",
    "print(x.ravel('F'))\n",
    "print(x.ravel('F')//2)\n",
    "x.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal probability: [p(x1=0), p(x1=1)] = [0.7 0.3]\n",
      "Marginal probability: [p(x2=0), p(x2=1)] = [0.6 0.4]\n",
      "p(x2=0 | x1=0) = 0.5714285714285715\n",
      "Expected value: [0.3 0.4]\n",
      "X_centered:\n",
      " [[-0.3  0.7 -0.3  0.7]\n",
      " [-0.4 -0.4  0.6  0.6]]\n",
      "Covariance matrix:\n",
      " [[ 0.21 -0.02]\n",
      " [-0.02  0.24]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# joint probability table\n",
    "p_table = np.array([[0.4, 0.3], [0.2, 0.1]])\n",
    "\n",
    "# each column of X contains a possible event. 1st row corresponds to x1,\n",
    "# 2nd row corresponds to x2\n",
    "#X = [[0 1 0 1],\n",
    "#     [0 0 1 1]]\n",
    "X = np.array([[0, 1, 0, 1], \n",
    "              [0, 0, 1, 1]])\n",
    "\n",
    "# p_table.ravel('F') = [0.4  0.2  0.3  0.1] are the joint probability values that\n",
    "# correspond to these columns\n",
    "\n",
    "# marginal probabilities: sum accross rows\n",
    "p_x1 = np.sum(p_table, axis=1)\n",
    "p_x2 = np.sum(p_table, axis=0)\n",
    "\n",
    "print('Marginal probability: [p(x1=0), p(x1=1)] = {}'.format(p_x1))\n",
    "print('Marginal probability: [p(x2=0), p(x2=1)] = {}'.format(p_x2))\n",
    "\n",
    "# conditional  p(x2 = 0 | x1 = 0)\n",
    "# p(A|B) = p(A \\intersect B) / p(B)\n",
    "p_x2equals0condx1equals0 = p_table[0,0] / p_x1[0]\n",
    "print('p(x2=0 | x1=0) = {}'.format(p_x2equals0condx1equals0))\n",
    "\n",
    "# expected value\n",
    "E_X = np.dot(X, p_table.ravel('F')) # ravel('F') while keeping column order\n",
    "print('Expected value: {}'.format(E_X))\n",
    "\n",
    "# covariance matrix\n",
    "X_centered = X - np.expand_dims(E_X, axis=1) # expand_dims is needed so that numpy is able to subtract the vector from the matrix\n",
    "print(\"X_centered:\\n {}\".format(X_centered))\n",
    "CovX = np.dot(np.dot(X_centered, np.diag(p_table.ravel('F'))), X_centered.T)\n",
    "print('Covariance matrix:\\n {}'.format(CovX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Write a PYTHON function `toyrnd` that expects the positive integer parameter `n` as its input and returns a matrix `X` of size `[2,n]`, containing `n` samples drawn independently from the distribution $p_X$, as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyrnd(n):\n",
    "    X_out = np.zeros((2,n))\n",
    "    Q = np.zeros((n,))\n",
    "    T = np.random.rand(n)\n",
    "     \n",
    "    # Interpreting [x1, x2] as binary number and Q as its decimal representation\n",
    "    Q[T>0.4] = 1\n",
    "    Q[T>0.7] = 2\n",
    "    Q[T>0.9] = 3\n",
    "    \n",
    "    X_out[0] = Q // 2 # floor division\n",
    "    X_out[1] = Q % 2 # modulus division\n",
    "    \n",
    "    return X_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Verify your results in a) by generating `10000` samples with `toyrnd` and computing the respective empirical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical marginal probability: [p(x1=0), p(x1=1)] = [0.7028 0.2972]\n",
      "Empirical marginal probability: [p(x2=0), p(x2=1)] = [0.603 0.397]\n",
      "Empirical conditional probability P(x2=0|x1=0): 0.5762663631189527\n",
      "Empirical expected value: [0.2972 0.397 ]\n",
      "Empirical covariance matrix:\n",
      " [[ 0.20887216 -0.0187884 ]\n",
      " [-0.0187884   0.239391  ]]\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "X_observed = toyrnd(N)\n",
    "# marginal probabilities\n",
    "p_X1equals0_empirical = np.array(np.sum(X_observed[0,:]==0))/N\n",
    "p_X1equals1_empirical = np.array(np.sum(X_observed[0,:]==1))/N\n",
    "p_X2equals0_empirical = np.array(np.sum(X_observed[1,:]==0))/N\n",
    "p_X2equals1_empirical = np.array(np.sum(X_observed[1,:]==1))/N\n",
    "\n",
    "p_x1_empirical = np.array([p_X1equals0_empirical, p_X1equals1_empirical])\n",
    "p_x2_empirical = np.array([p_X2equals0_empirical, p_X2equals1_empirical])\n",
    "\n",
    "print('Empirical marginal probability: [p(x1=0), p(x1=1)] = {}'.format(p_x1_empirical))\n",
    "print('Empirical marginal probability: [p(x2=0), p(x2=1)] = {}'.format(p_x2_empirical))\n",
    "\n",
    "# conditional probability\n",
    "X2condX1equals0 = X_observed[1, X_observed[0,:]==0]\n",
    "P_X2equals0condX1eqzals0_empirical = np.array(np.sum(X2condX1equals0 == 0)) / len(X2condX1equals0)\n",
    "print('Empirical conditional probability P(x2=0|x1=0):', P_X2equals0condX1eqzals0_empirical)\n",
    "# expected value\n",
    "E_X_empirical = np.sum(X_observed, axis=1)/N\n",
    "print('Empirical expected value: {}'.format(E_X_empirical))\n",
    "\n",
    "# covariance matrix\n",
    "CovX_empirical = np.dot(X_observed - np.expand_dims(E_X_empirical, axis=1), (X_observed - np.expand_dims(E_X_empirical, axis=1)).T) / N\n",
    "print('Empirical covariance matrix:\\n {}'.format(CovX_empirical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "The MNIST training set consists of handwritten digits from 0 to 9, stored as PNG files of size $28 \\times 28$ and indexed by label. Download the provided ZIP file from Moodle and make yourself familiar with the directory structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Grayscale images are typically described as matrices of `uint8` values. For numerical calculations, it is more sensible to work with floating point numbers. Load two (abitrary) images from the database and convert them to matrices `I1` and `I2` of `float64` values in the interval $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image min/max value: 0.0/255.0\n"
     ]
    }
   ],
   "source": [
    "import imageio.v2 as imageio\n",
    "\n",
    "# define to image paths which to import\n",
    "data_folder = './mnist_train/mnist/'\n",
    "\n",
    "impath1 = data_folder + 'd2/d2_0075.png'\n",
    "impath2 = data_folder + 'd3/d3_0013.png'\n",
    "\n",
    "# import and convert to numpy array\n",
    "I1 = np.array(imageio.imread(impath1)).astype(np.float64)\n",
    "I2 = np.array(imageio.imread(impath2)).astype(np.float64)\n",
    "\n",
    "# check values\n",
    "print('First image min/max value: {}/{}'.format(np.min(I1), np.max(I1)))\n",
    "\n",
    "# normalize values to [0,1]\n",
    "I1 = I1 / 255.\n",
    "I2 = I2 / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f945a25c040>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(I1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) The matrix equivalent of the euclidean norm $\\|\\cdot\\|_2$ is the Frobenius norm. For any matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, it is defined as\n",
    "\t\t\t\\begin{equation}\n",
    "\t\t\t    \\|\\mathbf{A}\\|_F = \\sqrt{\\mathrm{tr}(\\mathbf{A}^\\top \\mathbf{A})},\n",
    "\t\t\t\\end{equation}\n",
    "\t\t\twhere $\\mathrm{tr}$ denotes the trace of a matrix. Compute the distance $\\|\\mathbf{I}_1 - \\mathbf{I}_2\\|_F$ between the images `I1` and `I2` by using three different procedures in PYTHON:\t\t\t\n",
    "-  Running the `numpy.linalg.norm` function with the `'fro'` parameter\n",
    "-  Directly applying the above equation\n",
    "-  Computing the euclidean norm between the vectorized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Frobenius norm: 11.71589679029833\n",
      "Implemented Frobenius norm: 11.715896790298329\n",
      "Euclidean norm of vectorized images: 11.71589679029833\n"
     ]
    }
   ],
   "source": [
    "# using frobenius nor\n",
    "%timeit\n",
    "frob1 = np.linalg.norm(I1 - I2, 'fro')\n",
    "\n",
    "print('Numpy Frobenius norm: {}'.format(frob1))\n",
    "\n",
    "# using formula\n",
    "frob2 = np.sqrt(np.trace(np.matmul((I1 - I2), (I1 - I2).T)))\n",
    "\n",
    "print('Implemented Frobenius norm: {}'.format(frob2))\n",
    "# using euclidean norm of vectorized images\n",
    "frob3 = np.sqrt(np.dot((I1 - I2).ravel(), (I1 - I2).ravel()))\n",
    "print('Euclidean norm of vectorized images: {}'.format(frob3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) In the following, we want to solve a simple classification problem by applying *$k$-Nearest Neighbours*. To this end, choose two digit classes, e.g. $0$ and $1$, and load `n_train = 500` images from each class to the workspace. Convert them according to subtask a) and store them in vectorized form in the matrix `X_train` of size `[784, 2*n_train]`. Provide an indicator vector `Y_train` of length `2*n_train` that assigns the respective digit class label to each column of `X_train`.\n",
    "\n",
    "From each of the two classes, choose another set of `n_test=10` images and create the according matrices `X_test` and `Y_test`. Now, for each sample in the test set, determine the `k = 20` training samples with the smallest Frobenius distance to it and store their indices in the `2*n_test, k` matrix `NN`. Generate a vector `Y_kNN` containing the respective estimated class labels by performing a majority vote on `NN`. Compare the result with `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Computing Frobenius distances...\n",
      "Determining nearest neighbors...\n",
      "Ground truth label data:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Labels determined by kNN:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# chose which numbers to load:\n",
    "d_id1 = 2\n",
    "d_id2 = 3\n",
    "d = [d_id1, d_id2]\n",
    "\n",
    "# define # of training and testing samples\n",
    "n_train = 500\n",
    "n_test = 10\n",
    "k = 20\n",
    "\n",
    "# initialize data matrices\n",
    "X_train = np.zeros((784, 2*n_train))\n",
    "X_test = np.zeros((784, 2*n_test))\n",
    "\n",
    "print('Loading training data...')\n",
    "for j in range(0,n_train):\n",
    "    impath = data_folder + 'd' + str(d[0]) + '/d' + str(d[0]) + '_' + str(j+1).zfill(4) + '.png'\n",
    "    X_train[:,0*n_train+j] = np.array(imageio.imread(impath)).astype(float).ravel()/255\n",
    "    impath = data_folder + 'd' + str(d[1]) + '/d' + str(d[1]) + '_' + str(j+1).zfill(4) + '.png'\n",
    "    X_train[:,1*n_train+j] = np.array(imageio.imread(impath)).astype(float).ravel()/255\n",
    "        \n",
    "Y_train = np.concatenate((np.zeros(n_train), np.ones(n_train)))\n",
    "\n",
    "\n",
    "print('Loading test data...')\n",
    "for j in range(n_test):\n",
    "    impath = data_folder + 'd' + str(d[0]) + '/d' + str(d[0]) + '_' + str(n_train+j+1).zfill(4) + '.png'\n",
    "    X_test[:,0*n_test+j] = np.array(imageio.imread(impath)).astype(float).ravel()/255\n",
    "    impath = data_folder + 'd' + str(d[1]) + '/d' + str(d[1]) + '_' + str(n_train+j+1).zfill(4) + '.png'\n",
    "    X_test[:,1*n_test+j] = np.array(imageio.imread(impath)).astype(float).ravel()/255\n",
    "    \n",
    "Y_test = np.concatenate((np.zeros(n_test), np.ones(n_test)))\n",
    "\n",
    "print('Computing Frobenius distances...')\n",
    "\n",
    "D = np.zeros((2*n_test, 2*n_train))\n",
    "for i in range(2*n_test):\n",
    "    # compute norm of distance of test sample i to all training samples\n",
    "    D[i,:] = np.sqrt(np.sum((np.expand_dims(X_test[:,i], axis=1) - X_train) ** 2, axis=0))\n",
    "    \n",
    "print('Determining nearest neighbors...')\n",
    "# np.argsort outputs indices required for sorting\n",
    "NN = np.argsort(D, axis = 1)\n",
    "# we only need the k closest neighbors, hence, we cut off after k columns\n",
    "NN = NN[:,0:k]\n",
    "\n",
    "print('Ground truth label data:')\n",
    "print(Y_test.astype(float))\n",
    "\n",
    "# compute nearest neighbor labelling\n",
    "# sum over labels of k nearest training examples\n",
    "# and divide by k\n",
    "# if the resulting number is smaller than 0.5, we assign label 0\n",
    "# if the resulting number is greater, we assign label 1\n",
    "kNN_mask = np.sum(Y_train[NN], axis=1)/k >= 0.5\n",
    "# convert boolean to integer\n",
    "Y_kNN= kNN_mask.astype(float)\n",
    "\n",
    "print('Labels determined by kNN:')\n",
    "print(Y_kNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
